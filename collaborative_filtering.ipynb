{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "movie_names_data = pd.read_csv('./ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies = len(movie_names_data)\n",
    "n_user = len(ratings_data['userId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data = pd.merge(ratings_data, movie_names_data, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   userId  movieId  rating   timestamp             title  \\\n",
       "0       1        1     4.0   964982703  Toy Story (1995)   \n",
       "1       5        1     4.0   847434962  Toy Story (1995)   \n",
       "2       7        1     4.5  1106635946  Toy Story (1995)   \n",
       "3      15        1     2.5  1510577970  Toy Story (1995)   \n",
       "4      17        1     4.5  1305696483  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>847434962</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1106635946</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>1510577970</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1305696483</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "ratings_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "Y = ratings_data.rating\n",
    "user_enc = LabelEncoder()\n",
    "movie_enc = LabelEncoder()\n",
    "X = np.array([user_enc.fit_transform(ratings_data.userId),\n",
    "              movie_enc.fit_transform(ratings_data.title)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 'Toy Story (1995)')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "user_enc.classes_[4], movie_enc.classes_[8871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 8871] 4.0\n[4, 8871] 4.0\n[6, 8871] 4.5\n[14, 8871] 2.5\n[16, 8871] 4.5\n[17, 8871] 3.5\n[18, 8871] 4.0\n[20, 8871] 3.5\n[26, 8871] 3.0\n[30, 8871] 5.0\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X[:10], Y[:10]):\n",
    "    print(list(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(X)\n",
    "num_movies = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Activation, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    movie_input = Input(shape=[1], name=\"Book-Input\")\n",
    "    movie_embedding = Embedding(n_movies+1, 15, name=\"Book-Embedding\")(movie_input)\n",
    "    movie_vec = Flatten(name=\"Flatten-Books\")(movie_embedding)\n",
    "\n",
    "    user_input = Input(shape=[1], name=\"User-Input\")\n",
    "    user_embedding = Embedding(n_user+1, 15, name=\"User-Embedding\")(user_input)\n",
    "    user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "    \n",
    "    prod = Dot(name=\"Dot-Product\", axes=1)([user_vec, movie_vec])\n",
    "    \n",
    "    prod = Dense(32)(prod)\n",
    "    prod = Activation('relu')(prod)\n",
    "    prod = Dropout(0.5)(prod)\n",
    "\n",
    "    prod = Dense(16)(prod)\n",
    "    prod = Activation('relu')(prod)\n",
    "    prod = Dropout(0.5)(prod)\n",
    "    prod = Dense(1)(prod)\n",
    "\n",
    "\n",
    "    model = Model([user_input, movie_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/elmar/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "Train on 80668 samples, validate on 20168 samples\n",
      "Epoch 1/15\n",
      "80668/80668 [==============================] - 3s 39us/step - loss: 2.9608 - accuracy: 0.1559 - val_loss: 1.1596 - val_accuracy: 0.2001\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.15957, saving model to ./checkpoint\n",
      "Epoch 2/15\n",
      "80668/80668 [==============================] - 3s 38us/step - loss: 1.5467 - accuracy: 0.2117 - val_loss: 0.9161 - val_accuracy: 0.2781\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.15957 to 0.91608, saving model to ./checkpoint\n",
      "Epoch 3/15\n",
      "80668/80668 [==============================] - 3s 33us/step - loss: 1.1103 - accuracy: 0.2496 - val_loss: 0.9021 - val_accuracy: 0.2784\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.91608 to 0.90212, saving model to ./checkpoint\n",
      "Epoch 4/15\n",
      "80668/80668 [==============================] - 3s 34us/step - loss: 0.8174 - accuracy: 0.2926 - val_loss: 0.8864 - val_accuracy: 0.2906\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.90212 to 0.88638, saving model to ./checkpoint\n",
      "Epoch 5/15\n",
      "80668/80668 [==============================] - 3s 33us/step - loss: 0.6258 - accuracy: 0.3333 - val_loss: 0.8798 - val_accuracy: 0.2976\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.88638 to 0.87976, saving model to ./checkpoint\n",
      "Epoch 6/15\n",
      "80668/80668 [==============================] - 3s 42us/step - loss: 0.5369 - accuracy: 0.3644 - val_loss: 0.8808 - val_accuracy: 0.3007\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.87976\n",
      "Epoch 7/15\n",
      "80668/80668 [==============================] - 3s 43us/step - loss: 0.4993 - accuracy: 0.3803 - val_loss: 0.8870 - val_accuracy: 0.2972\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.87976\n",
      "Epoch 8/15\n",
      "80668/80668 [==============================] - 4s 46us/step - loss: 0.4778 - accuracy: 0.3924 - val_loss: 0.8956 - val_accuracy: 0.3025\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.87976\n",
      "Epoch 9/15\n",
      "80668/80668 [==============================] - 4s 48us/step - loss: 0.4652 - accuracy: 0.3987 - val_loss: 0.8991 - val_accuracy: 0.2981\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.87976\n",
      "Epoch 10/15\n",
      "80668/80668 [==============================] - 3s 42us/step - loss: 0.4520 - accuracy: 0.4016 - val_loss: 0.9038 - val_accuracy: 0.2997\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.87976\n",
      "Epoch 11/15\n",
      "80668/80668 [==============================] - 4s 47us/step - loss: 0.4504 - accuracy: 0.4066 - val_loss: 0.9226 - val_accuracy: 0.2994\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.87976\n",
      "Epoch 12/15\n",
      "80668/80668 [==============================] - 4s 51us/step - loss: 0.4407 - accuracy: 0.4093 - val_loss: 0.9209 - val_accuracy: 0.2983\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.87976\n",
      "Epoch 13/15\n",
      "80668/80668 [==============================] - 4s 50us/step - loss: 0.4321 - accuracy: 0.4134 - val_loss: 0.9360 - val_accuracy: 0.2983\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.87976\n",
      "Epoch 14/15\n",
      "80668/80668 [==============================] - 4s 46us/step - loss: 0.4282 - accuracy: 0.4151 - val_loss: 0.9267 - val_accuracy: 0.2990\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.87976\n",
      "Epoch 15/15\n",
      "80668/80668 [==============================] - 4s 44us/step - loss: 0.4188 - accuracy: 0.4201 - val_loss: 0.9371 - val_accuracy: 0.2973\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.87976\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./checkpoint',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "history = model.fit([X_train[:, 0], X_train[:, 1]], Y_train, \n",
    "            epochs=15, \n",
    "            verbose=1,\n",
    "            batch_size=64, \n",
    "            validation_data=([X_test[:, 0], X_test[:, 1]], Y_test), \n",
    "            callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[ 413, 8216],\n",
       "        [ 297, 8032],\n",
       "        [ 543, 1727],\n",
       "        [ 190, 2478],\n",
       "        [ 344,  221]]), 41008    2.0\n",
       " 94274    2.0\n",
       " 77380    5.0\n",
       " 29744    4.0\n",
       " 40462    4.0\n",
       " Name: rating, dtype: float64)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_test[:5], Y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test[:5, 0], X_test[:5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2.6292038]\n [2.9112046]\n [3.2737513]\n [3.3789482]\n [4.058033 ]] \n\n [2. 2. 5. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(predictions,\"\\n\\n\", Y_test[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"'Til There Was You (1997)\""
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "movie_enc.classes_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3.0, 1.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0]"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "extract_true_ratings(test_user_id, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_true_ratings(user_id, X_test):\n",
    "    \n",
    "    true_ratings = list()\n",
    "    for x, y in X_test:\n",
    "        if x == user_id:\n",
    "            rating = ratings_data[(ratings_data['userId'] == user_enc.classes_[user_id]) \\\n",
    "                & (ratings_data['title'] == movie_enc.classes_[y])]['rating'].values[0]\n",
    "            true_ratings.append(rating)\n",
    "\n",
    "    return true_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(user_id, X_test):\n",
    "    '''\n",
    "    given user id predict all ratings for movies\n",
    "    '''\n",
    "    user_data = ratings_data[ratings_data['userId'] == user_id]\n",
    "    movie_ids, movie_names, predictions, movie_genres = list(), list(), list(), list()\n",
    "    i = 0\n",
    "    for _id, movie_id in X_test:\n",
    "        if user_id == X_test[i][0]:\n",
    "            movie_ids.append(X_test[i, 1])\n",
    "            movie_names.append(movie_enc.classes_[movie_id])\n",
    "            pred = model.predict([ np.array([X_test[i, 0]]), np.array([X_test[i, 1]]) ])\n",
    "            predictions.append(pred[0][0])\n",
    "        i += 1\n",
    "    return movie_ids, movie_names, movie_genres, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = 7\n",
    "userid_rating_data = ratings_data[ratings_data['userId'] == test_user_id]\n",
    "# userid_rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids, movie_names, movie_genres, predictions = predict_ratings(test_user_id, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"user_id\": [test_user_id]*len(movie_ids),\n",
    "              \"movie_id\": movie_ids,\n",
    "              \"movie_name\":movie_names,\n",
    "              \"predicted_ratings\":predictions,\n",
    "              \"true_ratings\": extract_true_ratings(test_user_id, X_test) \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  user_id movie_id                                 movie_name  \\\n",
       "7       7     7523                Seven (a.k.a. Se7en) (1995)   \n",
       "6       7      713                                Babe (1995)   \n",
       "4       7     8982  Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "5       7     1337                          Braveheart (1995)   \n",
       "0       7     1091                       Birdcage, The (1996)   \n",
       "3       7      836                              Batman (1989)   \n",
       "1       7     9403             While You Were Sleeping (1995)   \n",
       "2       7     2663                             Ed Wood (1994)   \n",
       "\n",
       "  predicted_ratings true_ratings  \n",
       "7           4.67376            4  \n",
       "6           4.60559            5  \n",
       "4            4.2711            3  \n",
       "5           3.74487            3  \n",
       "0           3.66631            3  \n",
       "3           3.65645            3  \n",
       "1             2.708            3  \n",
       "2           2.25248            3  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>movie_name</th>\n      <th>predicted_ratings</th>\n      <th>true_ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7523</td>\n      <td>Seven (a.k.a. Se7en) (1995)</td>\n      <td>4.67376</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>713</td>\n      <td>Babe (1995)</td>\n      <td>4.60559</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>8982</td>\n      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n      <td>4.2711</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>1337</td>\n      <td>Braveheart (1995)</td>\n      <td>3.74487</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>1091</td>\n      <td>Birdcage, The (1996)</td>\n      <td>3.66631</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>836</td>\n      <td>Batman (1989)</td>\n      <td>3.65645</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>9403</td>\n      <td>While You Were Sleeping (1995)</td>\n      <td>2.708</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>2663</td>\n      <td>Ed Wood (1994)</td>\n      <td>2.25248</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "prediction_dataframe = pd.DataFrame.from_dict(dictionary, orient='index').transpose()\n",
    "prediction_dataframe.sort_values('predicted_ratings', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}